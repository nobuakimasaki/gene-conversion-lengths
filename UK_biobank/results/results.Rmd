---
title: "results"
output: html_document
date: "2025-04-22"
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)

l_psi <- read.csv("l_psi.csv")

res_null <- read.csv("res_null.csv")
res_sum <- read.csv("res_sum.csv")
res_mixture <- read.csv("res_mixture.csv") %>% arrange(NLL)
res_mixture <- res_mixture[1,]

# mean1 and mean2 only useful for mixture model
res_df <- rbind(res_null, res_sum, res_mixture)
res_df$mean1 <- 1/res_df$phi1
res_df$mean2 <- 1/res_df$phi2

# convert to long
long_est <- res_df %>%
  select(-X) %>%  # drop X column
  pivot_longer(
    cols = c(NLL, AIC, mean, w1, phi1, phi2, mean1, mean2),
    names_to = "variable",
    values_to = "est")

# ######### bootstrap #########  
# List all files starting with "bootstrap" and ending with a seed number
file_list <- list.files(pattern = "^bootstrap.*seed[0-9]+.*\\.csv$", full.names = TRUE)

# Load CSVs, remove the first column, and attach seed number
res_list <- lapply(file_list, function(file) {
  # Read CSV and drop first column
  df <- read.csv(file)

  # Extract seed number using regex
  seed <- sub(".*seed([0-9]+).*\\.csv$", "\\1", basename(file))

  # Add seed as a new column
  df$seed <- as.integer(seed)
  
  df$mean1 <- 1/df$phi1
  df$mean2 <- 1/df$phi2

  return(df)
})

# in each iteration of the bootstrap and for each model, get the estimates with the smallest NLL (only relevant for mixture)
res_boot <- do.call(rbind, res_list) %>%
  group_by(model, bootstrap, seed) %>%
  slice_min(NLL, with_ties = FALSE) %>%
  ungroup() %>%
  arrange(model, seed, bootstrap)

# assign different index for each seed and bootstrap
res_boot <- res_boot %>%
  mutate(index = group_indices(., seed, bootstrap)) 

# there should be 42*12*3 rows (seems ok)

# check results for each model
res_boot_null <- res_boot %>% filter(model == "null")
res_boot_sum <- res_boot %>% filter(model == "sum")
res_boot_mixture <- res_boot %>% filter(model == "mixture")

# limit bootstrap index to 500
res_boot <- res_boot %>% filter(index <= 500)
 
# Define desired quantiles
q_probs <- c(0.025, 0.975)
vars <- c("NLL", "AIC", "w1", "phi1", "phi2", "mean1", "mean2", "mean")
q_labels <- paste0("q", q_probs * 100)

# Compute quantiles grouped by model, wide format for quantiles
quantiles_by_model <- res_boot %>%
  group_by(model) %>%
  group_split() %>%
  map_dfr(function(subdf) {
    model_val <- unique(subdf$model)
    
    map_dfr(vars, function(v) {
      q_vals <- quantile(subdf[[v]], probs = q_probs, na.rm = TRUE)
      
      tibble(
        model = model_val,
        variable = v,
        q2.5 = q_vals[[1]],
        q97.5 = q_vals[[2]]
      )
    })
  })

res_df <- inner_join(long_est, quantiles_by_model)

res_AIC <- res_df %>% filter(variable == "AIC")
res_AIC$est[1]
res_AIC$est[2]
res_AIC$est[3]

res_AIC$est[1] - res_AIC$est[3]
```

```{r}
mixture_plot_df <- res_df %>% filter(model == "mixture")

ggplot(mixture_plot_df %>% filter(variable %in% c("mean", "mean1", "mean2", "w1")), aes(x = model, y = est)) +
  geom_point() +
  geom_errorbar(aes(ymin = q2.5, ymax = q97.5), width = 0.2) +
  facet_wrap(vars(variable), scales = "free_y") + 
  theme_bw() +
  labs(y = "Estimate (with 95% CI)", x = "Model")
```
```{r}
# Construct file paths for chromosomes 1 to 22
file_paths <- paste0("../data/chr", 1:22, ".ibdclust2cM_trim1_combinedoffsets_v6.inf_obs_tracts2")

# Read and bind all files into a single data frame
all_data <- map_dfr(file_paths, read.table, header = FALSE)
all_data$l <- all_data$V2 - all_data$V1 + 1

# Calculating various sample sizes
n1 <- sum(all_data$l == 1)
n <- nrow(all_data)
n
n1
(n-n1)
n1/n
(n-n1)/n

n1500 <- sum(all_data$l > 1500)
n1500
n1500/n

n_est <- sum(all_data$l != 1 & all_data$l <= 1500)
n_est
```

